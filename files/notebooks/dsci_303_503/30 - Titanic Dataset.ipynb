{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 30 - Titanic Dataset\n",
    "\n",
    "### The following topics are discussed in this notebook:\n",
    "* A complete example of using classificaiton models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset\n",
    "\n",
    "In this example, we will be working with the Titanic dataset. This dataset contains information about the 887 passengers on the voyage of the Titanic. Of the columns available, we will be particularly interested in the following:\n",
    "\n",
    "* **`Survived`** - Binary variable indicating whether or not the passenger survived the voyage. \n",
    "* **`Pclass`** - Categorical variable indicating the passenger class. \n",
    "* **`Sex`** - Categorical variable indicating the gender of the passenger. \n",
    "* **`Age`** - Age of the passenger.\n",
    "\n",
    "Our goal in this example will be to build a model for the purposes of predicting whether or not particular passengers survived the disaster based on their values for `Pclass`, `Sex`, and `Age`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Tools\n",
    "\n",
    "We will begin by importing the packages and tools that we will use in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "The data is stored in the tab-delimited file `titanic.txt`. We will load that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic.txt', sep='\\t')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually Inspect Data\n",
    "\n",
    "Before creating any models, we will use `matplotlib` to visually inspect the relationships between our features and our label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_survival_rate = np.sum((df.Sex == 'female') & (df.Survived == 1)) / np.sum(df.Sex == 'female')\n",
    "male_survival_rate = np.sum((df.Sex == 'male') & (df.Survived == 1)) / np.sum(df.Sex == 'male')\n",
    "sex_survival_rates = np.array([female_survival_rate, male_survival_rate])\n",
    "sex_death_rates = 1 - sex_survival_rates\n",
    "\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.bar(['Female', 'Male'], sex_survival_rates, label='Survived', \n",
    "        color='cornflowerblue', edgecolor='k')\n",
    "plt.bar(['Female', 'Male'], sex_death_rates, label='Died', \n",
    "        bottom=sex_survival_rates, color='Salmon', edgecolor='k')\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1.03,0.5))\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Survival Rate by Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_survival_rate = np.sum((df.Pclass == 1) & (df.Survived == 1)) / np.sum(df.Pclass == 1)\n",
    "class2_survival_rate = np.sum((df.Pclass == 2) & (df.Survived == 1)) / np.sum(df.Pclass == 2)\n",
    "class3_survival_rate = np.sum((df.Pclass == 3) & (df.Survived == 1)) / np.sum(df.Pclass == 3)\n",
    "class_survival_rates = np.array([class1_survival_rate, class2_survival_rate, class3_survival_rate])\n",
    "class_death_rates = 1 - class_survival_rates\n",
    "\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.bar(['Class 1', 'Class 2', 'Class 3'], class_survival_rates, label='Survived', \n",
    "        color='cornflowerblue', edgecolor='k')\n",
    "plt.bar(['Class 1', 'Class 2', 'Class 3'], class_death_rates, label='Died', \n",
    "        bottom=class_survival_rates, color='Salmon', edgecolor='k')\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1.03,0.5))\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Survival Rate by Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prop_surv = \n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.hist([df.Age.values[df.Survived == 1], df.Age.values[df.Survived == 0]], \n",
    "         bins=np.arange(0,90,5), label=['Survived','Died'], density=True,\n",
    "         edgecolor='k', alpha=0.6, color=['cornflowerblue','salmon'])\n",
    "plt.xticks(np.arange(0,90,5))\n",
    "plt.legend()\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Survival Rates by Age Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Numerical and Categorical Columns\n",
    "\n",
    "We will separate the numerical and categorical features into separate arrays so that we can apply one-hot encoding to the categorical features. We will also extract the label array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnum = df.iloc[:, [4]].values\n",
    "Xcat = df.iloc[:, [1, 3]].values.astype('str')\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Features\n",
    "\n",
    "We will now perform one-hot encoding on the categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(Xcat)\n",
    "Xenc   = encoder.transform(Xcat)\n",
    "\n",
    "print(Xenc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Feature Arrays\n",
    "\n",
    "We will now recombine our numerical feature array with our one-hot encoded categorical feature array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([Xnum, Xenc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "\n",
    "We will split the data into training, validation, and test sets, using a 70/15/15 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size = 0.3, random_state=1, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_hold, y_hold, test_size = 0.5, random_state=1, stratify=y_hold)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Logistic Regression Model\n",
    "\n",
    "In the cell below, we create a logistic regression model, and then calculate its training and validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(solver='lbfgs', penalty='none')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:  ', round(logreg_model.score(X_train, y_train),4))\n",
    "print('Validation Accuracy:', round(logreg_model.score(X_valid, y_valid),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Decision Tree Model\n",
    "\n",
    "We will now perform hyperparameter tuning to select the optimal value for the `max_depth` parameter for a decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = []\n",
    "va_acc = []\n",
    "\n",
    "depth_list = range(1,25)\n",
    "\n",
    "for d in depth_list:\n",
    "    temp_mod = DecisionTreeClassifier(max_depth=d, random_state=1)\n",
    "    temp_mod.fit(X_train, y_train)\n",
    "    tr_acc.append(temp_mod.score(X_train, y_train))\n",
    "    va_acc.append(temp_mod.score(X_valid, y_valid))\n",
    "\n",
    "plt.figure(figsize=([9, 6]))\n",
    "plt.plot(depth_list, tr_acc, label='Training Accuracy')\n",
    "plt.plot(depth_list, va_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Maximum Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(depth_list)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we get the best performance on the validation set when `max_depth=10`. We confirm this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_best = np.argmax(va_acc)\n",
    "best_md = depth_list[ix_best]\n",
    "print('Optimal Value of max_depth:', best_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create and score our decision tree model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(max_depth = best_md, random_state=1)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:  ', round(tree_model.score(X_train, y_train),4))\n",
    "print('Validation Accuracy:', round(tree_model.score(X_valid, y_valid),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Random Forest Model\n",
    "\n",
    "We will now create a random forest model consisting of 500 trees, each with a `max_depth` of 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_mod = RandomForestClassifier(n_estimators=500, max_leaf_nodes=32, random_state=1)\n",
    "\n",
    "forest_mod.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:  ', round(forest_mod.score(X_train, y_train),4))\n",
    "print('Validation Accuracy:', round(forest_mod.score(X_valid, y_valid),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Final Model\n",
    "\n",
    "The random forest model had the highest validation accuracy of any of our models, so we will select it to be our final model. We will now calculate this model's accuracy on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Set Accuracy:  ', round(forest_mod.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we display the confusion matrix for our test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = forest_mod.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "cm_df = pd.DataFrame(cm)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish this example by displaying the classification report for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
