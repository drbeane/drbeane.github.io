{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 29 - Diagnosing Breast Cancer\n",
    "\n",
    "### The following topics are discussed in this notebook:\n",
    "* A complete example of using classificaiton models to diagnose potentially cancerous tumors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsion Breast Cancer Dataset\n",
    "\n",
    "In this example, we will be working with the Wisconsin Breast Cancer Dataset. Each of the 569 observations in this dataset contains 30 measurements taken from images of cell nuclei drawn from a potentially cancerous breast mass. Each observation is labeled as being benign (B) or malignant (M).\n",
    "\n",
    "Our goal will be to build a model for the purposes of predicting the diagnosis of the tutor using the 30 measurements as features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Tools\n",
    "\n",
    "We will begin by importing the packages and tools that we will use in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "The data is stored in the coma-delimited file `breast_cancer.csv`. We will load that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('data/breast_cancer.csv', sep=',')\n",
    "print(wbc.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "We will extract the feature and label arrays, and split the dataset into training, validation and testing sets using a 60/20/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wbc.iloc[:,2:].values\n",
    "y = wbc.iloc[:,1].values\n",
    "\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.4, random_state=1, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_hold, y_hold, test_size=0.5, random_state=1, stratify=y_hold)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Logistic Regression Model\n",
    "\n",
    "In the cell below, we create a logistic regression model, and then calculate its training and validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mod = model_2 = LogisticRegression(solver='lbfgs', penalty='none', max_iter=5000)\n",
    "logreg_mod.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:  ', round(logreg_mod.score(X_train, y_train),4))\n",
    "print('Validation Accuracy:', round(logreg_mod.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Decision Tree Model\n",
    "\n",
    "We will now perform hyperparameter tuning to select the optimal value for the `max_depth` parameter for a decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = []\n",
    "va_acc = []\n",
    "\n",
    "depth_list = range(1,11)\n",
    "\n",
    "for d in depth_list:\n",
    "    temp_mod = DecisionTreeClassifier(max_depth=d, random_state=1)\n",
    "    temp_mod.fit(X_train, y_train)\n",
    "    tr_acc.append(temp_mod.score(X_train, y_train))\n",
    "    va_acc.append(temp_mod.score(X_valid, y_valid))\n",
    "    \n",
    "plt.figure(figsize=([6,4]))\n",
    "plt.plot(depth_list, tr_acc, label='Training Accuracy')\n",
    "plt.plot(depth_list, va_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we get the best performance on the validation set when `max_depth=2`. We confirm this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_best = np.argmax(va_acc)\n",
    "best_md = depth_list[ix_best]\n",
    "print('Optimal Value of max_depth:', best_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create and score our decision tree model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_mod = DecisionTreeClassifier(max_depth=best_md, random_state=1)\n",
    "tree_mod.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:  ', round(tree_mod.score(X_train, y_train),4))\n",
    "print('Validation Accuracy:', round(tree_mod.score(X_valid, y_valid),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Random Forest Model\n",
    "\n",
    "We will now create a random forest model consisting of 500 trees, each with a `max_depth` of 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_mod = RandomForestClassifier(n_estimators=500, max_depth=32, random_state=1)\n",
    "forest_mod.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:  ', round(forest_mod.score(X_train, y_train),4))\n",
    "print('Validation Accuracy:', round(forest_mod.score(X_valid, y_valid),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Final Model\n",
    "\n",
    "The logistic regression model had the highest validation accuracy of any of our models, so we will select it to be our final model. We will now calculate this model's accuracy on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Set Accuracy:', round(logreg_mod.score(X_test, y_test),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
