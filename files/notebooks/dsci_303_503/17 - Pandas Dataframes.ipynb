{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 17 - Pandas DataFrames\n",
    "\n",
    "### The following topics are discussed in this notebook:\n",
    "* The dataframe data type from the pandas package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "The pandas package provides us with the DataFrame data type for working with structured data, or in other words, data that is organized in a tabular format with defined rows and columns. \n",
    "\n",
    "We have previously seen two tools that can be used for working with structured data: 2D Numpy arrays and dictionaries. DataFrames provide the following advantages over these other data structures:\n",
    "\n",
    "1. The elements of a Numpy array must all be of the same data type. While individual columns of a pandas DataFrame must have a consistent data type, different columns can contain different types. \n",
    "\n",
    "2. Unlike a Numpy array, we can assign names to the columns and (less importantly) to the rows of a DataFrame. \n",
    "\n",
    "3. We have seen that we can use dictionaries to represent tabular data. For example, we can set the values in a dictionary to be lists representing columns, in which case the keys will represent column names. However, there would be no explicit concept of a row in such a setup. DataFrames explicitly define both rows and columns. \n",
    "\n",
    "It is a common convention to import pandas under the alias `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataFrame from a Dictionary\n",
    "\n",
    "We can create a pandas DataFrame from a dictionary in which the key-value pairs represent columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_dict = {\n",
    "    'eid':[214, 174, 126, 227, 151, 175, 193, 146],\n",
    "    'name':['Drew', 'Faye', 'Beth', 'Chad', 'Hana', 'Gary', 'Alex', 'Emma'],\n",
    "    'age':[25, 19, 42, 31, 25, 28, 31, 25],\n",
    "    'rate':[11.50, 12.30, 14.60, 12.50, None, 15.60, 13.50, 14.30],\n",
    "    'hours':[38, 32, 40, 29, 40, 36, 24, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = pd.DataFrame(employee_dict)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every DataFrame comes with a `head()` method that can be used to view the first few rows of the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Elements\n",
    "\n",
    "Every row and column in a pandas DataFrames has both a name, and a numerical index. We can use the `iloc[]` attribute to access DataFrame elements using column and row indices, and we can use `loc[]` to access elements using column and row names. \n",
    "\n",
    "Note that for the DataFrame we have created above, the numerical indices for the rows are the same as their names. This is common, but not required. We will see an example later where the row names are different from the numerical indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[4, 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Rows\n",
    "\n",
    "We can extract entire rows from a DataFrame using slicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[4,:]\n",
    "#employee_df.loc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Columns\n",
    "\n",
    "We can also use slicing to extract entire columns from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:,'name']\n",
    "#employee_df['name']\n",
    "#employee_df.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loc` and `iloc` indexing attributes support fancy indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:,['name','rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since columns and rows have a well-defined order in a DataFrame, we can also use slicing with the `loc` indexer to slice a range of columns using their column names. \n",
    "\n",
    "Notice that when performing this type of slicing, the column appearing after the colon IS included in the slice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:,'eid':'age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Columns\n",
    "\n",
    "We can use `loc` to add new columns to a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:,'pay'] = employee_df.loc[:,'rate'] * employee_df.loc[:,'hours']\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Operations\n",
    "\n",
    "DataFrames come equipped with several methods such as `sum()` and `mean()` for performing operations on columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:,['hours', 'pay']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[:,2:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "A common headache for anyone who works with data is encountering data sets with missing values. Pandas provides us with several tools for identifying and working with missing values. We will discuss some of those here. \n",
    "\n",
    "The `isnull()` method returns a DataFrame consisting of Boolean values that indicate the location of missing values within the original DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the `isnull()` and `sum()` methods to count the number of missing values in each row of a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dropna()` method removes from a DataFrame any rows that contain missing values. By default, this method returns a new DataFrame, leaving the original object untouched. However, if we set the parameter `inplace=True`, then the operation is performed on the original DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.dropna(inplace=True)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "We can use Boolean masking to filter DataFrames, just as with Numpy arrays.\n",
    "\n",
    "The code in the cell below filters `employee_df`, keeping only records for employees who worked more than 30 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = employee_df.loc[:,'hours'] > 30\n",
    "employee_df.loc[sel, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call above that the average age for employees in the data set was 28.25. In the cell below, we determine the average age of employees older than 25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = employee_df.loc[:,'age'] > 25\n",
    "employee_df.loc[sel, 'age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with Numpy arrays, we can use & and | to filter on multiple criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = (employee_df.loc[:,'rate'] < 13) & (employee_df.loc[:,'hours'] > 30)\n",
    "employee_df.loc[sel, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a New Index\n",
    "\n",
    "DataFrames refer to the collection of row names (somewhat confusingly) as the **index** of the DataFrame. In most cases, these row names will be set to be equal to the numerical indices of the rows. However, it is possible to set the \"index\" of a DataFrame to a column within a DataFrame \n",
    "\n",
    "In the cell below, we set `eid` to be the index of `employee_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.set_index('eid', inplace=True)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still use `iloc` to index rows and columns according to their numerical indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[:4, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we must use the correct row names when using `loc` to subset the DataFrame. Notice that the rows are kept in their original order, and are not reordered according to the new row names that we have set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:227, :'rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Records to a Data Frame\n",
    "\n",
    "We will now see how to add new records to a DataFrame. First, lets recall what `employee_df` DataFrame currently contains. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `loc` to add a new records with a specific row name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[232] = ['Iris', 34, 11.2, 30, 11.2 * 30]\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a DataFrame of new records with the same structure as our original DataFrame, and then combine the two using the `append()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records = pd.DataFrame({\n",
    "    'name':['Jake', 'Kate'],\n",
    "    'age':[36, 29],\n",
    "    'rate':[11.7, 12.4],\n",
    "    'hours':[34, 32],\n",
    "}, index=[251, 368])\n",
    "\n",
    "new_records.loc[:,'pay'] = new_records.loc[:,'rate'] * new_records.loc[:,'hours']\n",
    "\n",
    "new_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.append(new_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that `append()` returns a new DataFrame. It does not change either of the DataFrames being combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrame from List of Lists\n",
    "\n",
    "There are many ways to create DataFrames. At the beginning of this lesson, we saw how to create DataFrames from dictionaries. DataFrames can also be created from lists of lists. In this case, row and column names must be provided, or they will be set to be the same as the numerical indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoL = [[30, 3.7, 'Ant', True], \n",
    "       [24, 1.3, 'Bird', True], \n",
    "       [45, 2.6, 'Cat', False], \n",
    "       [18, 4.2, 'Dog', True]]\n",
    "\n",
    "unnamed_df = pd.DataFrame(LoL)\n",
    "print(unnamed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_df = pd.DataFrame(data = LoL,\n",
    "                        index = ['Row1', 'Row2', 'Row3', 'Row4'],\n",
    "                        columns = ['Col1', 'Col2', 'Col3', 'Col4'])\n",
    "print(named_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
